alertmanager:
  config:
    global:
      slack_api_url: ''
    route:
      group_by: [alertname, datacenter, app]
      group_wait: 30s
      group_interval: 5m
      repeat_interval: 5m
      receiver: 'slack-notifications'
      routes:
      - match:
          alertname: PodNotReady
        receiver: 'slack-notifications'
    receivers:
    - name: 'slack-notifications'
      slack_configs:
        - channel: '#prometheus-alerts'
          send_resolved: false
          icon_url: https://avatars3.githubusercontent.com/u/3380462
          title: |-
            [{{ .Status | toUpper }}{{ if eq .Status "firing" }}:{{ .Alerts.Firing | len }}{{ end }}] {{ .CommonLabels.alertname }}
          text: >-
           {{ range .Alerts -}}
           *Alert:* {{ .Annotations.title }}{{ if .Labels.severity }} - `{{ .Labels.severity }}`{{ end }}

           *Description:* {{ .Annotations.description }}

           *Details:*
             {{ range .Labels.SortedPairs }} â€¢ *{{ .Name }}:* `{{ .Value }}`
             {{ end }}
           {{ end }}

additionalPrometheusRules:
  - name: pods-rule
    groups:
      - name: pods
        rules:
          - alert: PodNotReady
            annotations:
              description: Pod {{ $labels.namespace }}/{{ $labels.pod }} has been in a non-ready state for longer than 5 min.
              title: PodNotReady
            expr: sum by (namespace, pod) (kube_pod_status_phase{phase=~"Pending|Unknown"}) > 0
            for: 5m
            labels:
              severity: critical